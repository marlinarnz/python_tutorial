{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Tutorial - Part 2\n",
    "\n",
    "Welcome to the second part of your pandas tutorial. \n",
    "\n",
    "In this tutorial you get to know:\n",
    "\n",
    "- Dataframes and series\n",
    "- Basic pandas functions for dataframes and series\n",
    "- How to store datatypes (int, float, string, etc) in pandas\n",
    "\n",
    "- Using the loc fundtion to display, filter, edit segments of a dataframe\n",
    "- How to deal with nan-values\n",
    "\n",
    "- Group by - functions and index slicing\n",
    "- Plotting and using magic commands in pandas\n",
    "\n",
    "- And more\n",
    "\n",
    "Since this is a jupyter notebook, you can edit and execute code directly in the notebook. If you need an intro to jupyter notebooks, have a look at this <a href=\"https://www.youtube.com/watch?v=HW29067qVWk\">video</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` and `numpy` libraries are core tools for all kinds of data handling and analysis in Python. `pandas` allows easy and quick handling of data in so-called DataFrames ([pandas tutorials](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/index.html)). `matplotlib` is used for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series - Basic functions\n",
    "\n",
    "A **series** is a one-dimansional array that can hold different types of data such as integers, float, strings, or objects. Every entry in the series has an index (label).\n",
    "\n",
    "The following is a simple example of a series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6\n",
       "1        8\n",
       "2       42\n",
       "3    26000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = pd.Series([6, 8, 42, 26000])\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tasks*\n",
    "1. Enter a float and a string value in the series and see what happens to the dtype property.\n",
    "2. Try accessing the index using `S.index` (S being the name of the series in this case) as a command. With `S.values`, you can see the entries in the series in list format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the index does not have to be numerical. You can also use strings as indices, as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = ['bicycle', 'tram', 'train', 'car']\n",
    "quantities = [320, 13, 59, 176]\n",
    "S = pd.Series(quantities, index=mode)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "1. Try accessing a specific index using `S['tram']` for example.\n",
    "2. Create another series with the same modes in series S but different quantities. Then observe what happens when you add these two series simply using `S + S2` for example.  \n",
    "3. To the new series S2, add new modes such as 'boat' and then add `S + S2` and observe what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to use lists to create a series. You can also pass a dictionary as input as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport = {'bicycle': 320,\n",
    "             'tram' : 13,\n",
    "             'train': 59,\n",
    "             'car': 176}\n",
    "transport_series = pd.Series(transport)\n",
    "transport_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function\n",
    "You can use apply to perform basic math operations on your series. To find out more about the parameters which you can pass to the apply function check out the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html\">pandas documentation page</a>. This is a very useful page to use for pandas as it also shows you all the other fucntions available for series inclusing all parameters which you pass to the fucntion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.791759\n",
       "1     2.079442\n",
       "2     3.737670\n",
       "3    10.165852\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can observe a key difference between stating `S.apply(np.log)` and `S = S.apply(np.log)`. In the first case you see the output of the function but it is not stored. The second suppresses the output but stores it in the variable. You then need to state `print(S)` or simply `S` to see the output. *Try this in the cell below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes - Basic functions\n",
    "\n",
    "In contrast to series, dataframes have **two dimensions** and therefore look like tables as you would use them in Excel. This makes pandas a very powerful python library as you can perform complex operations on large amounts of data fairly quick. Each column can be interpreted as a series and you can perform similar functions to a column as to series. Each column can have it's own data type (integer, float, string, object).\n",
    "\n",
    "### Creating a dataframe / Loading data\n",
    "\n",
    "You have several options to create dataframes. These include:\n",
    "\n",
    "- From several lists\n",
    "- From series\n",
    "- From dictionaries\n",
    "- From a csv file\n",
    "\n",
    "### Dataframe from lists\n",
    "In the example below, a dataframe is created using lists. The lists contain Eurostat data with the rail kilometers in Dutch provinces per year. The <a href=\"https://ec.europa.eu/eurostat/databrowser/view/tgs00113/default/table?lang=en\">source</a> here is the same as for the data used below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>196</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>366</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>456</td>\n",
       "      <td>454</td>\n",
       "      <td>486</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>127</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  194  194  196  200\n",
       "1  365  365  366  344\n",
       "2  456  454  486  446\n",
       "3   97   97  127  103"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regions = ['Utrecht','Noord_Holland','Zuid_Holland','Zeeland']\n",
    "Years = [2016, 2017, 2018, 2019]\n",
    "\n",
    "Rail_2016 = [194, 365, 456, 97]\n",
    "Rail_2017 = [194, 365, 454, 97]\n",
    "Rail_2018 = [196, 366, 486, 127]\n",
    "Rail_2019 = [200, 344, 446, 103]\n",
    "\n",
    "Rail_NL = pd.DataFrame(list(zip(Rail_2016,Rail_2017,Rail_2018,Rail_2019)))\n",
    "Rail_NL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this dataframe is not very informative as it does not have column headers or indices. \n",
    "\n",
    "**Task:** Using the two lists `Regions` and `Years`, assign **years as column headers and regions as indices**. You can do this while creating the dataframe by adding  `columns = ...` & `index = ...` or by setting the columns/index afterwards using `Rail_NL.columns = ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting data using loc \n",
    "\n",
    "You can select data by simply typing `Rail_NL[2016]`. However, this is a rather limited method to select data as you can only access whole columns. The most versatile method to select data is the `loc` as exemplified below. For more detailled information about `loc`, have a look <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html\">here</a>.\n",
    "\n",
    "*The commands below only work once you have completed the previous step.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Utrecht'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5b56a4d87542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRail_NL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Utrecht'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3737\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Utrecht'"
     ]
    }
   ],
   "source": [
    "Rail_NL.loc['Utrecht']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rail_NL.loc['Utrecht',2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rail_NL.loc[Rail_NL[2016]<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rail_NL.loc[(Rail_NL[2016]<200)&(Rail_NL[2019]>=150)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since selecting data is a core element of using pandas, there are many more ways to select and filter data for eample using `iloc`, `Index.Slice` (ofen abbreviated using `idx`), filtering and many more. The topic is complex and depends on your specific case. For some inspiration have a look at <a href=\"https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html\">this tutorial</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe from series\n",
    "\n",
    "Now we want to create a dataframe from series, where each row represents a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016    194\n",
       "2017    194\n",
       "2018    196\n",
       "2019    200\n",
       "2016    365\n",
       "2017    365\n",
       "2018    366\n",
       "2019    344\n",
       "2016    456\n",
       "2017    454\n",
       "2018    486\n",
       "2019    446\n",
       "2016     97\n",
       "2017     97\n",
       "2018    127\n",
       "2019    103\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utrecht = pd.Series([194, 194 , 196, 200],index=Years)\n",
    "Noord_Holland = pd.Series([365, 365, 366, 344],index=Years)\n",
    "Zuid_Holland = pd.Series([456, 454, 486, 446],index=Years)\n",
    "Zeeland = pd.Series([97, 97, 127, 103],index=Years)\n",
    "\n",
    "Rail_NL_series = pd.concat([Utrecht,Noord_Holland,Zuid_Holland,Zeeland])\n",
    "Rail_NL_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we aimed for. When concantenating data, the default is that all data is attached below using `axis = 0` which points downwards. \n",
    "\n",
    "**Task:** Since we want to concantenate rows, set `axis = 1` in the example above. This will add each series as one column. \n",
    "\n",
    "Instead of renaming the columns as mentioned above, you can also give the series a name before concantenating by adding the property `name='Utrecht'`. This is more safe as you are sure the correct header is assigned to each series.\n",
    "\n",
    "##### Transposing dataframe\n",
    "\n",
    "Be aware though! Contrary to the above, the data now display the region in the columns and the year in the row. You can simply change the orientation of the dataframe using the command `Rail_NL = Rail_NL.T` or by adding `.T` to the concantenation command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe from dictionaries\n",
    "\n",
    "An option that is very similar to creating a dataframe from series is to create a dataframe from a dictionary. Have a look at what is similar and what is different in the example below.\n",
    "\n",
    "**Task:** Fill the `...` correctly to create the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utrecht</th>\n",
       "      <th>Noord_Holland</th>\n",
       "      <th>Zuid_Holland</th>\n",
       "      <th>Zeeland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>194</td>\n",
       "      <td>365</td>\n",
       "      <td>456</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>194</td>\n",
       "      <td>365</td>\n",
       "      <td>454</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>196</td>\n",
       "      <td>366</td>\n",
       "      <td>486</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>200</td>\n",
       "      <td>344</td>\n",
       "      <td>446</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Utrecht  Noord_Holland  Zuid_Holland  Zeeland\n",
       "2016      194            365           456       97\n",
       "2017      194            365           454       97\n",
       "2018      196            366           486      127\n",
       "2019      200            344           446      103"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rail_km = {'Utrecht': [194, 194 , 196, 200],\n",
    "         'Noord_Holland': [365, 365, 366, 344],\n",
    "         'Zuid_Holland': [456, 454, 486, 446],\n",
    "         'Zeeland': [97, 97, 127, 103]\n",
    "        }\n",
    "\n",
    "Rail_NL_dict = pd.DataFrame(rail_km, index=Years)\n",
    "Rail_NL_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a benefit is that the columns already have names and you just need to pass the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe from CSVs\n",
    "Alternatively, you can also load data in bulk using a CSV file. In the example below, we load all data on rail kilometers for the Netherlands from 2008 to 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_NL_csv_original = pd.read_csv('estat_NL_rail_km.csv') \n",
    "rail_NL_csv_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe we created, regions are not entered with their name but with their <a href=\"https://de.wikipedia.org/wiki/NUTS:NL\">NUTS code</a>. These have two digits with the first representing the 'landsdeel' (part of the country) and the second the province. Below, we will rename these NUTS codes to the province names but before, we want to story the information of which 'landsdeel' each province belongs to. \n",
    "\n",
    "For this we will copy the geo column and then remove the last digit. For this we will use a **list comprehension**. List comprehensions are much faster than looping though all rows of a dataframe, espeically if the dataframe is large. \n",
    "\n",
    "`[:-1]` detailes which characters will be removed. If you would for instance write `[2:-1]`, the NL would also be removed. You can also do this. The number that remains, however, will still be of type string. For our case this is not an issue, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_NL_csv_original['landsdeel'] = rail_NL_csv_original['geo']\n",
    "rail_NL_csv_original['landsdeel'] = [i[:-1] for i in rail_NL_csv_original['landsdeel']]\n",
    "rail_NL_csv_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve readability, we will first use the dictionary below to rename the cells in `geo` column above.\n",
    "\n",
    "**Task:** Try to rename the NUTS codes in the above dataframe with the following command.\n",
    "\n",
    "`rail_NL_csv_original = rail_NL_csv_original.replace({\"geo\": NUTS})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTS_NL_reg = {'NL11': 'Groningen',\n",
    "        'NL12': 'Friesland',\n",
    "        'NL13': 'Drenthe',\n",
    "        'NL21': 'Overijssel',\n",
    "        'NL22': 'Gelderland',\n",
    "        'NL23': 'Flevoland',\n",
    "        'NL31': 'Utrecht',\n",
    "        'NL32': 'Noord-Holland',\n",
    "        'NL33': 'Zuid-Holland',\n",
    "        'NL34': 'Zeeland',\n",
    "        'NL41': 'Noord-Brabant',\n",
    "        'NL42': 'Limburg'}\n",
    "rail_NL_csv_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Now <a href=\"https://de.wikipedia.org/wiki/NUTS:NL\">look up</a> the names for each landsdeel, create another dictionary translating the NUTS code to each landsdeel and write the code to rename the entries in column `landsdeel` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pivot Function\n",
    "But we still have data that we do not need and we would like to see the years as the column names and regaions as row indices. We could now use the `.drop` function to drop the columns which we do not need. But this would not solve the problem with our column names. For this we need to **pivot** our data.\n",
    "\n",
    "**Task:** In the code below enter the correct column headers of `rail_NL_csv_orignal` to pivot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_NL_csv = pd.pivot_table(rail_NL_csv_original, values = '...' , index = ['landsdeel', 'geo'], columns = '...')\n",
    "rail_NL_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-index and index slicer\n",
    "By entering two columns as the index in the pivot operation, we have created a two-level multi-index. <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html\">Multi-indexes</a> are very useful to structure data and access specific entries, especially in large dataframes. To select data we will use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.IndexSlice.html\">index slicing</a> which was already mentioned above.\n",
    "\n",
    "To shorten the code, we first declare `idx`. Within idx, you specify each level of the multi-index that you want to display seperated by a comma. To display all entries in a level simply enter `:`.\n",
    "\n",
    "You may need to adjust the `WEST-NEDERLAND` according to the  spelling you used in your dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "rail_NL_csv.loc[idx['WEST-NEDERLAND', :], 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below you can also acces multiple entries within one level at once. Also `loc` allows you to specify multiple columns using `:` if they are of a numerical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_NL_csv.loc[idx['WEST-NEDERLAND', ['Utrecht','Zeeland']], 2016:2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Now write an and index slicer where you select all rows from NOORD-NEDERLAND (NL1) and OOST-NEDERLAND (NL2) from 2008 to 2012. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by\n",
    "\n",
    "One way to analyze our data is aggregation. In Pandas this works though grouping the data and then performing functions on it. \n",
    "\n",
    "Grouping in pandas is less intutive as the object that is greated during grouping is not directly visualizible. You first need to translate it back into a readable format for example by performing  function on it and saving the output to a new or an exiting dataframe.\n",
    "\n",
    "Have a look at the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_rail = rail_NL_csv.groupby(['landsdeel']).agg(['mean',sum,'count'])\n",
    "NL_rail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** You can now use your indexing skills acquired above to set the `sum` and `mean` entries to integer. The command for this conversion is `.astype(int)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **improve the reability** of the table it is helpful to transpose the dataframe (as you learned earlier) using `.T`. Another way is using the `.stack` function, as displayed below. Save this version of the dataframe as you will use it later in the section on plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_stacked = NL_rail.stack(0)\n",
    "NL_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Now try to find the mean and standard deviation (command `std`) for the four landsdeel entries across all years. You will also have to practice your indexing skills for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to go beyong the content in this tutorial have a look <a href=\"https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\">here</a> for a more indepth tutorial of grouping in pandas.\n",
    "\n",
    "One way to practice your skills would be to download another dataset from the <a href=\"https://ec.europa.eu/eurostat/databrowser/view/tgs00113/default/table?lang=en\">source</a> to compare and group the data on country level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting & magic commands\n",
    "\n",
    "To plot our data we will use a magic command from python. These are very useful commands that shorted the code you need to write and allow you to use additional functionality like identifying the currect directoriy you work in using `%pwd`. If you enter `%lsmagic` you can see all magic commands jupyter notebook uses. Magic commands with a single `%` are line magic that have an effect for remainder of the notebook, wherears magic commands iwht a double `%%` only count for that cell.\n",
    "\n",
    "For more on magic commands, have a look at this <a href=\"https://www.youtube.com/watch?v=HW29067qVWk\">video</a> from minute 16 onwards.\n",
    "\n",
    "### Initializing matplotlib\n",
    "We already imported the matplotlib python library above. To enable us to display plots directly in a jupyther notebook, it is necessary to execute the following magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "rail_NL_csv.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current set-up of the graph is not very useful as the years are displayed as lines, there are no captions for the y-axis and it is not clear what is displayed on the x-axis.\n",
    "\n",
    "We can transpose the data (`.T`) to disply the years on the x-axis.\n",
    "\n",
    "Generally, you should first save the plot to a variable, then customize the axis, legend etc. and then use the command `plt.show()` to display the plot. The second line in the code below pushes the legend outside the plot. You can play around with the parameters to learn more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = rail_NL_csv.T.plot()\n",
    "plt.legend(title='Region',loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is not very informative or readable. We can use an index slicers to plot a selection of the data. Matplotlib also supports different chart types like barcharts, scatterplots, histograms, or boxplots.\n",
    "\n",
    "**Tasks:** \n",
    "\n",
    "- Add `kind='bar',stacked=True` inside the plot to see a bar plot. By adding `kind='barh` instead, the bar chart becomes horizontal. Also move the legend outside the plot and rename is usefully.\n",
    "\n",
    "- Also try adding `plt.ylabel = ...` in a new line to label the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_NL_csv.loc[idx['NL3',:], :].T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful chart type is a boxblot, which you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_NL_csv.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying grouped data\n",
    "Now, the groups which we created earlier come in useful. We can separate the outputs we generated in seperate plots.\n",
    "\n",
    "**Task:** Select only ofe of the four regions, add useful labels, move the legend out of the plots to make the plots readable and useful. It would also be an option to display the data as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_stacked.plot(subplots=True, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more info about visualization with matplotlib have a look <a href=\"https://pandas.pydata.org/pandas-docs/version/0.13/visualization.html\">here</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial was created by Luja von KÃ¶ckritz in June 2021."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
